"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[66],{151:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"meta/glossary","title":"Glossary of Robotics Terms","description":"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook. Terms are organized alphabetically for easy reference.","source":"@site/docs/meta/glossary.md","sourceDirName":"meta","slug":"/meta/glossary","permalink":"/Hackthon_SpecKitPlus/docs/meta/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/shaheryarshah/Hackthon_SpecKitPlus/edit/main/docs/docs/meta/glossary.md","tags":[],"version":"current","frontMatter":{}}');var s=o(4848),i=o(8453);const r={},a="Glossary of Robotics Terms",c={},l=[{value:"A",id:"a",level:2},{value:"B",id:"b",level:2},{value:"C",id:"c",level:2},{value:"D",id:"d",level:2},{value:"E",id:"e",level:2},{value:"F",id:"f",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"J",id:"j",level:2},{value:"K",id:"k",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"O",id:"o",level:2},{value:"P",id:"p",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2},{value:"Y",id:"y",level:2},{value:"Z",id:"z",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"glossary-of-robotics-terms",children:"Glossary of Robotics Terms"})}),"\n",(0,s.jsx)(n.p,{children:"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook. Terms are organized alphabetically for easy reference."}),"\n",(0,s.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Actuator"}),": A mechanical device that converts energy (electrical, hydraulic, or pneumatic) into motion. Common types include servomotors, stepper motors, and hydraulic cylinders."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Affordance"}),": The possibility of action offered by an object or environment to an agent. In robotics, it refers to what actions are possible with or on an object."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Artificial Intelligence (AI)"}),": The simulation of human intelligence processes by machines, especially computer systems. In robotics, AI enables perception, decision-making, and learning capabilities."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Autonomous Robot"}),": A robot that can operate independently without human intervention, making decisions based on its sensors and programming."]}),"\n",(0,s.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Behavior-Based Robotics"}),": An approach to robotics that structures robot control around collections of task-oriented behaviors that operate in parallel."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Bipedal Locomotion"}),": The act of walking on two legs, a key challenge in humanoid robotics involving balance and gait planning."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Body Schema"}),": A representation of the body and its parts that allows a robot to understand its configuration and plan movements accordingly."]}),"\n",(0,s.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Center of Mass (CoM)"}),": The point where the total mass of a body may be assumed to be concentrated for the purpose of analyzing motion and balance."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Collision Detection"}),": The computational problem of detecting the intersection of two or more objects, crucial for robot safety and navigation."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Compliance Control"}),": A control approach that allows robots to adapt to environmental forces by adjusting their position or force output."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Computer Vision"}),": A field of artificial intelligence that trains computers to interpret and understand visual information from the world."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Control Loop"}),": A feedback mechanism where a system continuously measures its output, compares it to a desired reference, and adjusts its input accordingly."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Covariance"}),": A measure of how much two random variables change together, used in robotics for uncertainty representation."]}),"\n",(0,s.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Deep Learning"}),": A subset of machine learning that uses neural networks with multiple layers to extract features and make decisions."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Degrees of Freedom (DOF)"}),": The number of independent movements or parameters that define the configuration of a mechanical system."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Dynamics"}),": The study of forces and torques and their effect on motion. Robot dynamics models how forces cause movement."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Dynamic Movement Primitives (DMP)"}),": A mathematical framework for representing and generating movements, useful for learning and reproducing robot behaviors."]}),"\n",(0,s.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Embodied Artificial Intelligence"}),": AI systems that interact with the physical world through a body, emphasizing the role of physical interaction in intelligence."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Embodied Cognition"}),": The theory that cognitive processes are influenced by the body's interactions with the environment."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"End Effector"}),": The device at the end of a robot arm that interacts with the environment, such as a gripper or tool."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Epuck"}),": A small mobile robot platform commonly used in education and research."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Ethics in Robotics"}),": The study of moral issues in the design, manufacture, use, and treatment of robots."]}),"\n",(0,s.jsx)(n.h2,{id:"f",children:"F"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Forward Kinematics"}),": The process of determining the position and orientation of the end effector given the joint angles of a robot."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Forward Model"}),": A predictive model that estimates the sensory consequences of motor commands, used for control and learning."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Friction Compensation"}),": Techniques to account for and counteract friction forces in robot control systems."]}),"\n",(0,s.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Gazebo"}),": A 3D simulation environment for robotics that provides accurate physics simulation and rendering capabilities."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Gaussian Noise"}),": Statistical noise having a probability density function equal to that of the normal distribution, commonly used to model sensor noise."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Gripper"}),": A device used by robots to grasp and hold objects, analogous to a human hand."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Ground Truth"}),": The actual state of the world, often used as a reference for evaluating robot perception and localization."]}),"\n",(0,s.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Haptic Feedback"}),": The use of touch and motion feedback to interact with virtual or remote environments."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hardware-in-the-Loop (HIL)"}),": A testing method that involves physical components in a simulated environment."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),": The study of interactions between humans and robots, including communication, collaboration, and trust."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Humanoid Robot"}),": A robot with a physical structure resembling the human body, typically featuring a head, torso, two arms, and two legs."]}),"\n",(0,s.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Inertial Measurement Unit (IMU)"}),": An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Inverse Kinematics"}),": The process of determining the joint angles required to achieve a desired end-effector position and orientation."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Inverse Dynamics"}),": The computation of forces and torques required to achieve a desired motion, based on the robot's dynamics model."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Isaac Sim"}),": NVIDIA's robotics simulation application built on the Omniverse platform, designed for photorealistic simulation."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS"}),": A collection of hardware-accelerated perception and navigation packages for ROS 2, optimized for NVIDIA GPUs."]}),"\n",(0,s.jsx)(n.h2,{id:"j",children:"J"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Jacobian Matrix"}),": A matrix that contains first-order partial derivatives of a vector-valued function, used in robotics to relate joint velocities to end-effector velocities."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Joint Space"}),": The space defined by the robot's joint angles, as opposed to Cartesian space."]}),"\n",(0,s.jsx)(n.h2,{id:"k",children:"K"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Kinematics"}),": The branch of mechanics concerned with the motion of objects without reference to the forces that cause the motion."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Kinodynamic Planning"}),": Motion planning that considers both kinematic and dynamic constraints of a robot."]}),"\n",(0,s.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"LIDAR (Light Detection and Ranging)"}),": A remote sensing method that uses light in the form of a pulsed laser to measure distances."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Linear Inverted Pendulum Model (LIPM)"}),": A simplified model for bipedal walking that represents the robot's center of mass as a point mass on a massless rod."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Localization"}),": The process of determining the robot's position and orientation in a known or unknown environment."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Low-level Control"}),": Control systems that manage the direct actuation of robot joints or motors, typically running at high frequencies."]}),"\n",(0,s.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Manipulation"}),": The ability of a robot to purposefully control objects in its environment using its end effectors."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mapping"}),": The process of creating a representation of the environment, typically for navigation or interaction purposes."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mobile Robot"}),": A robot that is capable of locomotion through its environment."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Motion Planning"}),": The process of determining a sequence of movements to achieve a goal while avoiding obstacles."]}),"\n",(0,s.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Navigation"}),": The process of planning and executing robot motion to move from one location to another."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Neural Network"}),": A computing system inspired by the human brain, used in robotics for perception, control, and learning."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Non-holonomic Constraint"}),": A constraint that restricts the direction of motion, common in wheeled robots that cannot move sideways."]}),"\n",(0,s.jsx)(n.h2,{id:"o",children:"O"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Obstacle Avoidance"}),": The capability of a robot to detect and avoid obstacles in its environment."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Occupancy Grid"}),": A probabilistic model of the environment represented as a grid of cells indicating the probability of occupancy."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Odometry"}),": The use of data from motion sensors to estimate change in position over time."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Open Source Robotics Foundation (OSRF)"}),": The organization that develops and maintains Gazebo and other open-source robotics software."]}),"\n",(0,s.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Path Planning"}),": The process of finding a sequence of positions that connect an initial state to a goal state."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Perception"}),": The ability of a robot to interpret and understand its environment through sensors."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Physical Artificial Intelligence"}),": AI systems that interact with the physical world, emphasizing embodied interaction and real-world tasks."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"PID Controller"}),": A control loop feedback mechanism that calculates an error value as the difference between desired and measured values."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Point Cloud"}),": A set of data points in space, typically representing the external surface of an object, used in 3D perception."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Probabilistic Robotics"}),": An approach to robotics that explicitly represents and handles uncertainty in robot perception and action."]}),"\n",(0,s.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Range Sensor"}),": A sensor that measures distances to objects, such as LIDAR, sonar, or structured light systems."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reachability Analysis"}),": The process of determining which positions a robot's end effector can reach."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Real-Time Control"}),": Control systems that must respond to sensor inputs and update actuator commands within strict timing constraints."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reinforcement Learning"}),": A type of machine learning where agents learn to make decisions by performing actions and receiving rewards or penalties."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Robot Operating System (ROS)"}),": A flexible framework for writing robot software that provides services for hardware abstraction, device drivers, and message passing."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Robotics Middleware"}),": Software infrastructure that provides services to robotic applications, such as communication, resource management, and device abstraction."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"ROS 2"}),": The second generation of the Robot Operating System, designed for production robotics applications."]}),"\n",(0,s.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Sensor Fusion"}),": The process of combining data from multiple sensors to improve the accuracy and reliability of information."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Sim-to-Real Transfer"}),": The application of policies trained in simulation to real-world robotic systems."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"}),": The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"State Estimation"}),": The process of estimating the internal state of a system from sensor measurements and control inputs."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stereo Vision"}),": A method of determining distance by comparing images from two cameras, mimicking human binocular vision."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Identification"}),": The process of developing mathematical models of dynamic systems from measured data."]}),"\n",(0,s.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Task Planning"}),": The process of decomposing high-level goals into sequences of actions that achieve the goals."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Trajectory"}),": A path through space with timing information, specifying how to move from one configuration to another."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Trajectory Optimization"}),": The process of finding an optimal path or trajectory for a robot to follow."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tactile Sensor"}),": A sensor that measures information obtained by touch, important for robotic manipulation."]}),"\n",(0,s.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Unity"}),": A 3D development platform that can be used for robotics visualization and simulation."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Universal Robot (UR)"}),": A series of collaborative robots that can work alongside humans."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"URDF (Unified Robot Description Format)"}),": An XML format for representing robot models, including kinematic and dynamic properties."]}),"\n",(0,s.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Velodyne"}),": A company that produces LIDAR sensors widely used in robotics and autonomous vehicles."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Vision System"}),": A robot system that uses cameras and computer vision algorithms for perception and navigation."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Vision-Language-Action (VLA)"}),": An integrated approach combining visual perception, language understanding, and robotic action execution."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Virtual Reality (VR)"}),": A simulated experience that can be similar to or completely different from the real world, sometimes used in robot teleoperation."]}),"\n",(0,s.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Wheel Odometry"}),": Odometry based on measuring the rotation of wheels to estimate motion."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Whole-Body Control"}),": A control approach that simultaneously considers all the robot's degrees of freedom for coordination and balance."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Workspace"}),": The volume of space that a robot manipulator can reach with its end effector."]}),"\n",(0,s.jsx)(n.h2,{id:"y",children:"Y"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Yaw"}),": The rotation of a robot around its vertical axis, one of the three primary orientations (roll, pitch, yaw)."]}),"\n",(0,s.jsx)(n.h2,{id:"z",children:"Z"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Zero Moment Point (ZMP)"}),": A critical concept in bipedal locomotion representing the point where the net moment of the ground reaction forces is zero."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>a});var t=o(6540);const s={},i=t.createContext(s);function r(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);